{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学习尝试用theano搭建多层GRU网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 7005 on context None\n",
      "Mapped name None to device cuda: GeForce GTX 1050 Ti (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import itertools\n",
    "import nltk\n",
    "import operator\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from numpy.random import uniform as uniform\n",
    "from numpy import sqrt as sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_dir data\\save\n",
      "Start preparing training data ...\n",
      "Reading lines...cornell movie-dialogs corpus\n",
      "datafile...data/训练数据.txt\n",
      "Read 529586 sentence pairs\n",
      "Trimmed to 114074 sentence pairs\n",
      "Counting words...\n",
      "Counted words: 86302\n",
      "\n",
      "pairs:\n",
      "['这场 也 有 免费 的 直播 ？ 达胜', '达胜 24 直播 网有 免费 高清 的']\n",
      "['这种 饼 也 只有 奉先能 吃 不然 又 闷平 交出 签名 车牌号', '交出 签名 车牌号 juc - 635']\n"
     ]
    }
   ],
   "source": [
    "corpus_name = \"cornell movie-dialogs corpus\"\n",
    "corpus = os.path.join(\"data\", corpus_name)\n",
    "\n",
    "def printLines(file, n=10):\n",
    "    with open(file, 'rb') as datafile:\n",
    "        lines = datafile.readlines()\n",
    "    for line in lines[:n]:\n",
    "        print(line)\n",
    "def loadLines(fileName, fields):\n",
    "    lines = {}\n",
    "    with open(fileName, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            #if (line % 100 == 0):\n",
    "            #print(line)\n",
    "            values = line.split(\" +++$+++ \")\n",
    "           # print(values)\n",
    "            # Extract fields\n",
    "            lineObj = {}\n",
    "            #print(fields)\n",
    "            for i, field in enumerate(fields):\n",
    "                #if (i % 100 == 0):\n",
    "                #print(i,field,values[i])\n",
    "                lineObj[field] = values[i]\n",
    "            lines[lineObj['lineID']] = lineObj\n",
    "    return lines\n",
    "\n",
    "\n",
    "# Groups fields of lines from `loadLines` into conversations based on *movie_conversations.txt*\n",
    "def loadConversations(fileName, lines, fields):\n",
    "    conversations = []\n",
    "    with open(fileName, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            values = line.split(\" +++$+++ \")\n",
    "            # Extract fields\n",
    "            #print(values)\n",
    "            convObj = {}\n",
    "            for i, field in enumerate(fields):\n",
    "                convObj[field] = values[i]\n",
    "            # Convert string to list (convObj[\"utteranceIDs\"] == \"['L598485', 'L598486', ...]\")\n",
    "            utterance_id_pattern = re.compile('L[0-9]+')\n",
    "            lineIds = utterance_id_pattern.findall(convObj[\"utteranceIDs\"])\n",
    "            # Reassemble lines\n",
    "            convObj[\"lines\"] = []\n",
    "            for lineId in lineIds:\n",
    "                convObj[\"lines\"].append(lines[lineId])\n",
    "            conversations.append(convObj)\n",
    "    return conversations\n",
    "\n",
    "\n",
    "# Extracts pairs of sentences from conversations\n",
    "def extractSentencePairs(conversations):\n",
    "    qa_pairs = []\n",
    "    for conversation in conversations:\n",
    "        # Iterate over all the lines of the conversation\n",
    "        for i in range(len(conversation[\"lines\"]) - 1):  # We ignore the last line (no answer for it)\n",
    "            inputLine = conversation[\"lines\"][i][\"text\"].strip()\n",
    "            targetLine = conversation[\"lines\"][i+1][\"text\"].strip()\n",
    "            # Filter wrong samples (if one of the lists is empty)\n",
    "            if inputLine and targetLine:\n",
    "                qa_pairs.append([inputLine, targetLine])\n",
    "    return qa_pairs\n",
    "# Default word tokens\n",
    "PAD_token = 0  # Used for padding short sentences\n",
    "SOS_token = 1  # Start-of-sentence token\n",
    "EOS_token = 2  # End-of-sentence token\n",
    "#trimmed  是否修剪\n",
    "class Voc:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3  # Count SOS, EOS, PAD\n",
    "#\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    # Remove words below a certain count threshold过滤低频词\n",
    "    def trim(self, min_count):\n",
    "        if self.trimmed:\n",
    "            return\n",
    "        self.trimmed = True\n",
    "\n",
    "        keep_words = []\n",
    "\n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "\n",
    "        print('keep_words {} / {} = {:.4f}'.format(\n",
    "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
    "        ))\n",
    "\n",
    "        # Reinitialize dictionaries\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3 # Count default tokens\n",
    "\n",
    "        for word in keep_words:\n",
    "            self.addWord(word)\n",
    "MAX_LENGTH = 15  # Maximum sentence length to consider需要考虑的最大句子长度\n",
    "datafile = os.path.join( \"data/训练数据.txt\")\n",
    "\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    #lower()到小写\n",
    "    #Python strip() 方法用于移除字符串头尾指定的字符（默认为空格或换行符）或字符序列。\n",
    "    s = s.lower().strip()\n",
    "    #与大多数编程语言相同，知正则表达式里使用\"\\\"作为转义字符，这就可能造成反斜杠困扰。假如你需要匹配文本中的字符\"\\\"，\n",
    "    #那么使用编程道语言表示的正则表达式版里将需要4个反斜杠\"\\\\\\\\\"：前两个和后两个分别用于在编程语言里转义成反斜杠，\n",
    "    #转换成两个反斜杠后再在正则表达式里转义成一个反斜杠。Python里的原生字符串很好地解决了这个问题，\n",
    "    #这个例子中的正则表达式可以使用r\"\\\\\"表示。同样，匹配一个数字的\"\\\\d\"可以写成r\"\\d\"。有了原生字符串，\n",
    "    #你再也不用担心是不是漏写了反斜杠，写出来的表达式也更直观。\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[,']+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "# Read query/response pairs and return a voc object读取查询/响应对并返回voc对象\n",
    "def readVocs(datafile, corpus_name):\n",
    "    print(\"Reading lines...\"+corpus_name)\n",
    "    print(\"datafile...\"+datafile)\n",
    "    # Read the file and split into lines\n",
    "\n",
    "    lines = open(datafile, encoding='utf-8').\\\n",
    "    read().strip().split('\\n')#这里反斜杆是续行符\n",
    "    # Split every line into pairs and normalize 将每一行分成几对并归一化\n",
    "    pairs = [[normalizeString(s) for s in l.split('【*分割*】')] for l in lines]\n",
    "    #实例化类Voc\n",
    "    voc = Voc(corpus_name)\n",
    "    return voc, pairs\n",
    "\n",
    "# Returns True iff both sentences in a pair 'p' are under the MAX_LENGTH threshold\n",
    "#如果对“ p”中的两个句子都在MAX_LENGTH阈值以下，则返回True\n",
    "def filterPair(p):\n",
    "    # Input sequences need to preserve the last word for EOS token输入序列需要保留EOS令牌的最后一个字\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "# Filter pairs using filterPair condition使用filterPair条件的过滤器对\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "# Using the functions defined above, return a populated voc object and pairs list\n",
    "# 使用上面定义的函数，返回填充的voc对象和配对列表\n",
    "def loadPrepareData(corpus_name, datafile, save_dir):\n",
    "    print(\"Start preparing training data ...\")\n",
    "    voc, pairs = readVocs(datafile, corpus_name)#这里读取会话对\n",
    "    print(\"Read {!s} sentence pairs\".format(len(pairs)))#格式化字符串操作\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        voc.addSentence(pair[0])\n",
    "        voc.addSentence(pair[1])\n",
    "    print(\"Counted words:\", voc.num_words)\n",
    "    return voc, pairs\n",
    "\n",
    "\n",
    "# Load/Assemble voc and pairs加载/组装voc和对\n",
    "save_dir = os.path.join(\"data\", \"save\")\n",
    "print(\"save_dir\",save_dir)\n",
    "#os.path.join 运行路径中加入新的文件夹\n",
    "\n",
    "voc, pairs = loadPrepareData(corpus_name, datafile, save_dir)\n",
    "# Print some pairs to validate打印一些对以进行验证\n",
    "print(\"\\npairs:\")\n",
    "for pair in pairs[:2]:\n",
    "    print(pair)#pairs数组 成员是字符串数组\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_words 13451 / 86299 = 0.1559\n",
      "Trimmed from 114074 pairs to 40345, 0.3537 of total\n"
     ]
    }
   ],
   "source": [
    "MIN_COUNT = 10    # Minimum word count threshold for trimming\n",
    "\n",
    "def trimRareWords(voc, pairs, MIN_COUNT):\n",
    "    # Trim words used under the MIN_COUNT from the voc语音中MIN_COUNT下使用的修饰词\n",
    "    voc.trim(MIN_COUNT)\n",
    "    # Filter out pairs with trimmed words过滤掉带有修饰词的词对\n",
    "    keep_pairs = []\n",
    "    for pair in pairs:\n",
    "        input_sentence = pair[0]\n",
    "        output_sentence = pair[1]\n",
    "        keep_input = True\n",
    "        keep_output = True\n",
    "        # Check input sentence检查输入句子\n",
    "        for word in input_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_input = False\n",
    "                break\n",
    "        # Check output sentence\n",
    "        for word in output_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_output = False\n",
    "                break\n",
    "\n",
    "        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n",
    "        if keep_input and keep_output:\n",
    "            keep_pairs.append(pair)\n",
    "\n",
    "    print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n",
    "    return keep_pairs\n",
    "\n",
    "\n",
    "# Trim voc and pairs\n",
    "pairs = trimRareWords(voc, pairs, MIN_COUNT)\n",
    "SENTENCE_START_TOKEN = \"SENTENCE_START\"\n",
    "SENTENCE_END_TOKEN = \"SENTENCE_END\"\n",
    "UNKNOWN_TOKEN = \"UNKNOWN_TOKEN\"\n",
    "b=nltk.word_tokenize(pairs[0][0])\n",
    "\n",
    "会话对_分割1= [nltk.word_tokenize('SENTENCE_START '+pair[0]+' SENTENCE_END')+nltk.word_tokenize('SENTENCE_START '+pair[1]+' SENTENCE_END') for pair in pairs]\n",
    "会话对_分割= [ [nltk.word_tokenize('SENTENCE_START '+对+' SENTENCE_END')for 对 in pair]for pair in pairs]\n",
    "词频 = nltk.FreqDist(itertools.chain(*会话对_分割1))\n",
    "词汇数量=len(词频.items())\n",
    "\n",
    "词汇_降序 = sorted(词频.items(), key=lambda x: (x[1], x[0]), reverse=True)[:词汇数量-2]\n",
    "词汇_升序 = sorted(词汇_降序, key=operator.itemgetter(1))\n",
    "下标_到_单词 = [\"<MASK/>\", UNKNOWN_TOKEN] + [x[0] for x in 词汇_升序]\n",
    "单词_到_下标 = dict([(w, i) for i, w in enumerate(下标_到_单词)])\n",
    "for i, 分割 in enumerate(会话对_分割):\n",
    "    会话对_分割[i] =[[w if w in 单词_到_下标 else UNKNOWN_TOKEN for w in 部]for 部 in 分割]\n",
    "X_train = np.asarray([[单词_到_下标[w] for w in 分割[0][:-1]] for 分割 in 会话对_分割])\n",
    "y_train = np.asarray([[单词_到_下标[w] for w in 分割[1][1:]] for 分割 in 会话对_分割])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def 打包训练数据(输入,输出,包数=10,包大小=10):\n",
    "    包_输入_集=[]\n",
    "    输入_遮罩_集=[]\n",
    "    for 数1 in range(包数):\n",
    "        包_输入=[]\n",
    "        P=[i for i in range(数1*包大小,数1*包大小+(包大小))]\n",
    "\n",
    "        NP=输入[P]\n",
    "        记录长度=0\n",
    "        for j in NP:\n",
    "            if len(j)>记录长度:\n",
    "                记录长度=len(j)\n",
    "        计数=0\n",
    "        for j in NP:\n",
    "            补齐数=记录长度-len(j)\n",
    "            输入_遮罩_临=np.ones(len(j))\n",
    "            for k in range(补齐数):\n",
    "                j.append(0)\n",
    "                输入_遮罩_临=np.append(输入_遮罩_临,0.)\n",
    "            #包_输入.append(j)\n",
    "        #print(len(包_输入))\n",
    "            if 计数==0:\n",
    "                包_输入=np.array(j).reshape(记录长度,1)\n",
    "                输入_遮罩=输入_遮罩_临.reshape(记录长度,1)\n",
    "            else:\n",
    "                输入_遮罩=np.concatenate((输入_遮罩,输入_遮罩_临.reshape(记录长度,1)),axis=1)\n",
    "                包_输入=np.concatenate((包_输入,np.array(j).reshape(记录长度,1)),axis=1)\n",
    "            计数+=1\n",
    "        包_输入_集.append(包_输入) \n",
    "        输入_遮罩_集.append(输入_遮罩)\n",
    "        \n",
    "    输出_遮罩_集=[]\n",
    "    包_输出_集=[]\n",
    "    for 数1 in range(包数):\n",
    "        包_输出=[]\n",
    "        P=[i for i in range(数1*包大小,数1*包大小+(包大小))]\n",
    "\n",
    "        NP=输出[P]\n",
    "        记录长度=0\n",
    "        for j in NP:\n",
    "            if len(j)>记录长度:\n",
    "                记录长度=len(j)\n",
    "        计数=0\n",
    "        for j in NP:\n",
    "            补齐数=记录长度-len(j)\n",
    "            输出_遮罩_临=np.ones(len(j))\n",
    "            for k in range(补齐数):\n",
    "                j.append(0)\n",
    "                输出_遮罩_临=np.append(输出_遮罩_临,0.)\n",
    "            if 计数==0:\n",
    "                包_输出=np.array(j).reshape(记录长度,1)\n",
    "                输出_遮罩=输出_遮罩_临.reshape(记录长度,1)\n",
    "            else:\n",
    "                \n",
    "                输出_遮罩=np.concatenate((输出_遮罩,输出_遮罩_临.reshape(记录长度,1)),axis=1)\n",
    "                包_输出=np.concatenate((包_输出,np.array(j).reshape(记录长度,1)),axis=1)\n",
    "            计数+=1\n",
    "        包_输出_集.append(包_输出)\n",
    "        输出_遮罩_集.append(输出_遮罩)\n",
    "    return 包_输入_集 , 包_输出_集 ,输入_遮罩_集,输出_遮罩_集\n",
    "\n",
    "包_输入 , 包_输出,输入_遮罩_集,输出_遮罩_集=打包训练数据(X_train,y_train,200,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class 预处理_正交():\n",
    "\tdef __init__(self, 词向量尺寸=100, 隐藏层尺寸=300):\n",
    "\t\tself.隐藏层尺寸 = 隐藏层尺寸\n",
    "\n",
    "\t\tE = uniform(-sqrt(1. / 词向量尺寸), sqrt(1. / 词向量尺寸), (隐藏层尺寸, 词向量尺寸))\n",
    "\t\tself.E = theano.shared(name='E', value=E.astype(theano.config.floatX))\n",
    "\t\tself.mE = theano.shared(name='mE', value=np.zeros(E.shape).astype(theano.config.floatX))\n",
    "\t\tself.参数 = [self.E]\n",
    "\t\tself.rms = [self.mE]\n",
    "\tdef 前向传播(self,输入):\n",
    "\n",
    "\t\tdef 前向_单步(输入_E,E_1):\n",
    "\t\t\t输出_E = E_1[:,输入_E]\n",
    "\t\t\treturn 输出_E\n",
    "\n",
    "\t\t单层输出, updates = theano.scan(\n",
    "\t\t\tfn = 前向_单步,\n",
    "\t\t\tsequences = [ 输入],\n",
    "\t\t\tnon_sequences = [self.E]\n",
    "\t\t\t)\n",
    "\t\treturn 单层输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_单位_集束():\n",
    "\tdef __init__(self,  隐藏层尺寸=300, 求导深度=-1):\n",
    "\t\tself.隐藏层尺寸 = 隐藏层尺寸\n",
    "\t\tself.求导深度 = 求导深度\n",
    "\n",
    "\t\tU = np.random.uniform(-np.sqrt(1. / 隐藏层尺寸), np.sqrt(1. / 隐藏层尺寸), (3 * 隐藏层尺寸, 隐藏层尺寸))\n",
    "\t\tW = np.random.uniform(-np.sqrt(1. / 隐藏层尺寸), np.sqrt(1. / 隐藏层尺寸), (3 * 隐藏层尺寸, 隐藏层尺寸))\n",
    "\n",
    "\t\tself.U = theano.shared(name='U', value=U.astype(theano.config.floatX))\n",
    "\t\tself.W = theano.shared(name='W', value=W.astype(theano.config.floatX))\n",
    "\t\tself.mU = theano.shared(name='mU', value=np.zeros(U.shape).astype(theano.config.floatX))\n",
    "\t\tself.mW = theano.shared(name='mW', value=np.zeros(W.shape).astype(theano.config.floatX))\n",
    "\t\tself.参数 = [self.W, self.U]\n",
    "\t\tself.rms= [self.mW, self.mU]\n",
    "\tdef 前向传播(self,输入,遮罩,集束量,隐层_单步_0=None):\n",
    "\t\tif 隐层_单步_0 == None:\n",
    "\t\t\t隐层_单步_0=T.zeros((self.隐藏层尺寸,集束量))\n",
    "#\t\t\t隐层_单步_0 = T.alloc(np.asarray(0., dtype=theano.config.floatX), self.隐藏层尺寸, 集束量)\n",
    "\t\tdef 前向_单步( 输入_E, 遮罩,隐层_单步_前,W,U,隐藏层尺寸):\n",
    "\t\t\t更新门 = T.nnet.hard_sigmoid(U[0:隐藏层尺寸, :].dot(输入_E) + W[0:隐藏层尺寸, :].dot(隐层_单步_前))\n",
    "\t\t\t重置门 = T.nnet.hard_sigmoid(\n",
    "\t\t\t\tU[1 * 隐藏层尺寸:2 * 隐藏层尺寸, :].dot(输入_E) + W[1 * 隐藏层尺寸:2 * 隐藏层尺寸, :].dot(\n",
    "\t\t\t\t\t隐层_单步_前))\n",
    "\t\t\t记忆单元 = T.tanh(\n",
    "\t\t\t\tU[2 * 隐藏层尺寸:3 * 隐藏层尺寸, :].dot(输入_E) + W[2 * 隐藏层尺寸:3 * 隐藏层尺寸, :].dot(\n",
    "\t\t\t\t\t隐层_单步_前 * 重置门))\n",
    "\t\t\t隐层_单步 = (T.ones_like(更新门) - 更新门) * 记忆单元 + 更新门 * 隐层_单步_前\n",
    "\t\t\t隐层_单步 = 遮罩[None,:]*隐层_单步 + (1.0 - 遮罩)[None,:]*隐层_单步_前            \n",
    "\t\t\treturn 隐层_单步\n",
    "\t\t单层输出, updates = theano.scan(\n",
    "\t\t\tfn = 前向_单步,\n",
    "\t\t\ttruncate_gradient=self.求导深度,\n",
    "\t\t\tsequences = [ 输入,遮罩],\n",
    "\t\t\toutputs_info = [隐层_单步_0],\n",
    "\t\t\tnon_sequences = [self.W, self.U,self.隐藏层尺寸]\n",
    "\t\t\t)\n",
    "\t\treturn 单层输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_注意力():\n",
    "\tdef __init__(self,  隐藏层尺寸=300, 注意力尺寸=300,求导深度=-1):\n",
    "\t\tself.隐藏层尺寸 = 隐藏层尺寸\n",
    "\t\tself.求导深度 = 求导深度\n",
    "\n",
    "\t\tW = np.random.uniform(-np.sqrt(1. / np.sqrt(注意力尺寸*隐藏层尺寸)), np.sqrt(1. / np.sqrt(注意力尺寸*隐藏层尺寸)), (注意力尺寸, 隐藏层尺寸))\n",
    "\t\tV = np.random.uniform(-np.sqrt(1. / np.sqrt(注意力尺寸)), np.sqrt(1. / np.sqrt(注意力尺寸)), (注意力尺寸))\n",
    "\n",
    "\t\tself.W = theano.shared(name='W', value=W.astype(theano.config.floatX))\n",
    "\t\tself.V = theano.shared(name='V', value=V.astype(theano.config.floatX))\n",
    "\t\tself.mW = theano.shared(name='mW', value=np.zeros(W.shape).astype(theano.config.floatX))\n",
    "\t\tself.mV = theano.shared(name='mV', value=np.zeros(V.shape).astype(theano.config.floatX))\n",
    "\t\tself.参数 = [self.W, self.V]\n",
    "\t\tself.rms= [self.mW, self.mV]\n",
    "\tdef 前向传播(self,输入):\n",
    "\t\tdef 前向_单步_1( 输入_E,W,V):\n",
    "\n",
    "\t\t\tE = V.dot(T.tanh(W.dot(输入_E)))\n",
    "\n",
    "\t\t\treturn E\n",
    "\t\tE, updates = theano.scan(\n",
    "\t\t\tfn = 前向_单步_1,\n",
    "\t\t\ttruncate_gradient=self.求导深度,\n",
    "\t\t\tsequences = [ 输入],\n",
    "\t\t\tnon_sequences = [self.W, self.V]\n",
    "\t\t\t)\n",
    "\t\tE_sum=T.sum(E,axis=0)\n",
    "\t\tdef 前向_单步_2( E,E_sum):\n",
    "           \n",
    "\t\t\t注意力_分=E/E_sum\n",
    "\n",
    "\t\t\treturn 注意力_分\n",
    "\t\t注意力分配, updates = theano.scan(\n",
    "\t\t\tfn = 前向_单步_2,\n",
    "\t\t\ttruncate_gradient=self.求导深度,\n",
    "\t\t\tsequences = [ E],\n",
    "\t\t\tnon_sequences = [E_sum]\n",
    "\t\t\t)\n",
    "\t\tdef 前向_单步_3( 输入_E,注意力_分):\n",
    "\t\t\tAH_分=注意力_分*输入_E \n",
    "             \n",
    "\t\t\treturn AH_分                      \n",
    "\t\tAH_分_集, updates = theano.scan(\n",
    "\t\t\tfn = 前向_单步_3,\n",
    "\t\t\ttruncate_gradient=self.求导深度,\n",
    "\t\t\tsequences = [输入, 注意力分配]\n",
    "\t\t\t)\n",
    "#\t\tAH_分_集 = theano.printing.Print('this is AH_分_集 value')(AH_分_集)\n",
    "\t\t隐层_新=T.sum(AH_分_集,axis=0)\n",
    "\t\treturn 隐层_新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_单位_集束_A():\n",
    "\tdef __init__(self,  隐藏层尺寸=300, 求导深度=-1):\n",
    "\t\tself.隐藏层尺寸 = 隐藏层尺寸\n",
    "\t\tself.求导深度 = 求导深度\n",
    "\n",
    "\t\tU = np.random.uniform(-np.sqrt(1. / 隐藏层尺寸), np.sqrt(1. / 隐藏层尺寸), (3 * 隐藏层尺寸, 隐藏层尺寸))\n",
    "\t\tW = np.random.uniform(-np.sqrt(1. / 隐藏层尺寸), np.sqrt(1. / 隐藏层尺寸), (3 * 隐藏层尺寸, 隐藏层尺寸))\n",
    "\n",
    "\t\tself.U = theano.shared(name='U', value=U.astype(theano.config.floatX))\n",
    "\t\tself.W = theano.shared(name='W', value=W.astype(theano.config.floatX))\n",
    "\t\tself.mU = theano.shared(name='mU', value=np.zeros(U.shape).astype(theano.config.floatX))\n",
    "\t\tself.mW = theano.shared(name='mW', value=np.zeros(W.shape).astype(theano.config.floatX))\n",
    "\t\tself.参数 = [self.W, self.U]\n",
    "\t\tself.rms= [self.mW, self.mU]\n",
    "\tdef 前向传播(self,输入,遮罩,集束量,隐层_单步_0=None):\n",
    "\t\tif 隐层_单步_0 == None:\n",
    "\t\t\t隐层_单步_0=T.zeros((self.隐藏层尺寸,集束量))\n",
    "#\t\t\t隐层_单步_0 = T.alloc(np.asarray(0., dtype=theano.config.floatX), self.隐藏层尺寸, 集束量)\n",
    "\t\tdef 前向_单步( 输入_E, 遮罩,隐层_单步_前,W,U,隐藏层尺寸):\n",
    "\t\t\t更新门 = T.nnet.hard_sigmoid(U[0:隐藏层尺寸, :].dot(输入_E) + W[0:隐藏层尺寸, :].dot(隐层_单步_前))\n",
    "\t\t\t重置门 = T.nnet.hard_sigmoid(\n",
    "\t\t\t\tU[1 * 隐藏层尺寸:2 * 隐藏层尺寸, :].dot(输入_E) + W[1 * 隐藏层尺寸:2 * 隐藏层尺寸, :].dot(\n",
    "\t\t\t\t\t隐层_单步_前))\n",
    "\t\t\t记忆单元 = T.tanh(\n",
    "\t\t\t\tU[2 * 隐藏层尺寸:3 * 隐藏层尺寸, :].dot(输入_E) + W[2 * 隐藏层尺寸:3 * 隐藏层尺寸, :].dot(\n",
    "\t\t\t\t\t隐层_单步_前 * 重置门))\n",
    "\t\t\t隐层_单步 = (T.ones_like(更新门) - 更新门) * 记忆单元 + 更新门 * 隐层_单步_前\n",
    "#\t\t\t隐层_单步 = 遮罩[None,:]*隐层_单步 + (1.0 - 遮罩)[None,:]*隐层_单步_前            \n",
    "\t\t\treturn 隐层_单步\n",
    "\t\t单层输出, updates = theano.scan(\n",
    "\t\t\tfn = 前向_单步,\n",
    "\t\t\ttruncate_gradient=self.求导深度,\n",
    "\t\t\tsequences = [ 输入,遮罩],\n",
    "\t\t\toutputs_info = [隐层_单步_0],\n",
    "\t\t\tnon_sequences = [self.W, self.U,self.隐藏层尺寸]\n",
    "\t\t\t)\n",
    "\t\treturn 单层输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_单位2_集束():\n",
    "\tdef __init__(self,  隐藏层尺寸=300, 求导深度=-1):\n",
    "\t\tself.隐藏层尺寸 = 隐藏层尺寸\n",
    "\t\tself.求导深度 = 求导深度\n",
    "\n",
    "\t\tU = np.random.uniform(-np.sqrt(1. / 隐藏层尺寸), np.sqrt(1. / 隐藏层尺寸), (3 * 隐藏层尺寸, 隐藏层尺寸))\n",
    "\t\tW = np.random.uniform(-np.sqrt(1. / 隐藏层尺寸), np.sqrt(1. / 隐藏层尺寸), (3 * 隐藏层尺寸, 隐藏层尺寸))\n",
    "\n",
    "\t\tself.U = theano.shared(name='U', value=U.astype(theano.config.floatX))\n",
    "\t\tself.W = theano.shared(name='W', value=W.astype(theano.config.floatX))\n",
    "\t\tself.mU = theano.shared(name='mU', value=np.zeros(U.shape).astype(theano.config.floatX))\n",
    "\t\tself.mW = theano.shared(name='mW', value=np.zeros(W.shape).astype(theano.config.floatX))\n",
    "\t\tself.参数 = [self.W, self.U]\n",
    "\t\tself.rms= [self.mW, self.mU]\n",
    "\tdef 前向传播(self,遮罩,集束量,隐层_单步_0=None):\n",
    "\t\tif 隐层_单步_0 == None:\n",
    "\t\t\t隐层_单步_0=T.zeros((self.隐藏层尺寸,集束量))\n",
    "#\t\t\t隐层_单步_0 = T.alloc(np.asarray(0., dtype=theano.config.floatX), self.隐藏层尺寸, 集束量)\n",
    "\t\tdef 前向_单步( 遮罩,隐层_单步_前,W,U,隐藏层尺寸):\n",
    "\t\t\t更新门 = T.nnet.hard_sigmoid(U[0:隐藏层尺寸, :].dot(隐层_单步_前) + W[0:隐藏层尺寸, :].dot(隐层_单步_前))\n",
    "\t\t\t重置门 = T.nnet.hard_sigmoid(\n",
    "\t\t\t\tU[1 * 隐藏层尺寸:2 * 隐藏层尺寸, :].dot(隐层_单步_前) + W[1 * 隐藏层尺寸:2 * 隐藏层尺寸, :].dot(\n",
    "\t\t\t\t\t隐层_单步_前))\n",
    "\t\t\t记忆单元 = T.tanh(\n",
    "\t\t\t\tU[2 * 隐藏层尺寸:3 * 隐藏层尺寸, :].dot(隐层_单步_前) + W[2 * 隐藏层尺寸:3 * 隐藏层尺寸, :].dot(\n",
    "\t\t\t\t\t隐层_单步_前 * 重置门))\n",
    "\t\t\t隐层_单步 = (T.ones_like(更新门) - 更新门) * 记忆单元 + 更新门 * 隐层_单步_前\n",
    "\t\t\t隐层_单步 = 遮罩[None,:]*隐层_单步 + (1.0 - 遮罩)[None,:]*隐层_单步_前 \n",
    "\t\t\treturn 隐层_单步\n",
    "\t\t单层输出, updates = theano.scan(\n",
    "\t\t\tfn = 前向_单步,\n",
    "\t\t\tsequences = [ 遮罩],\n",
    "\t\t\ttruncate_gradient=self.求导深度,\n",
    "\t\t\toutputs_info = [隐层_单步_0],\n",
    "\t\t\tnon_sequences = [self.W, self.U,self.隐藏层尺寸])\n",
    "\t\treturn 单层输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_单位2_集束_A():\n",
    "\tdef __init__(self,  隐藏层尺寸=300, 求导深度=-1):\n",
    "\t\tself.隐藏层尺寸 = 隐藏层尺寸\n",
    "\t\tself.求导深度 = 求导深度\n",
    "\n",
    "\t\tU = np.random.uniform(-np.sqrt(1. / 隐藏层尺寸), np.sqrt(1. / 隐藏层尺寸), (3 * 隐藏层尺寸, 隐藏层尺寸))\n",
    "\t\tW = np.random.uniform(-np.sqrt(1. / 隐藏层尺寸), np.sqrt(1. / 隐藏层尺寸), (3 * 隐藏层尺寸, 隐藏层尺寸))\n",
    "\n",
    "\t\tself.U = theano.shared(name='U', value=U.astype(theano.config.floatX))\n",
    "\t\tself.W = theano.shared(name='W', value=W.astype(theano.config.floatX))\n",
    "\t\tself.mU = theano.shared(name='mU', value=np.zeros(U.shape).astype(theano.config.floatX))\n",
    "\t\tself.mW = theano.shared(name='mW', value=np.zeros(W.shape).astype(theano.config.floatX))\n",
    "\t\tself.参数 = [self.W, self.U]\n",
    "\t\tself.rms= [self.mW, self.mU]\n",
    "\tdef 前向传播(self,遮罩,集束量,隐层_单步_0=None):\n",
    "\t\tif 隐层_单步_0 == None:\n",
    "\t\t\t隐层_单步_0=T.zeros((self.隐藏层尺寸,集束量))\n",
    "#\t\t\t隐层_单步_0 = T.alloc(np.asarray(0., dtype=theano.config.floatX), self.隐藏层尺寸, 集束量)\n",
    "\t\tdef 前向_单步( 遮罩,隐层_单步_前,W,U,隐藏层尺寸):\n",
    "\t\t\t更新门 = T.nnet.hard_sigmoid(U[0:隐藏层尺寸, :].dot(隐层_单步_前) + W[0:隐藏层尺寸, :].dot(隐层_单步_前))\n",
    "\t\t\t重置门 = T.nnet.hard_sigmoid(\n",
    "\t\t\t\tU[1 * 隐藏层尺寸:2 * 隐藏层尺寸, :].dot(隐层_单步_前) + W[1 * 隐藏层尺寸:2 * 隐藏层尺寸, :].dot(\n",
    "\t\t\t\t\t隐层_单步_前))\n",
    "\t\t\t记忆单元 = T.tanh(\n",
    "\t\t\t\tU[2 * 隐藏层尺寸:3 * 隐藏层尺寸, :].dot(隐层_单步_前) + W[2 * 隐藏层尺寸:3 * 隐藏层尺寸, :].dot(\n",
    "\t\t\t\t\t隐层_单步_前 * 重置门))\n",
    "\t\t\t隐层_单步 = (T.ones_like(更新门) - 更新门) * 记忆单元 + 更新门 * 隐层_单步_前\n",
    "#\t\t\t隐层_单步 = 遮罩[None,:]*隐层_单步 + (1.0 - 遮罩)[None,:]*隐层_单步_前 \n",
    "\t\t\treturn 隐层_单步\n",
    "\t\t单层输出, updates = theano.scan(\n",
    "\t\t\tfn = 前向_单步,\n",
    "\t\t\tsequences = [ 遮罩],\n",
    "\t\t\ttruncate_gradient=self.求导深度,\n",
    "\t\t\toutputs_info = [隐层_单步_0],\n",
    "\t\t\tnon_sequences = [self.W, self.U,self.隐藏层尺寸])\n",
    "\t\treturn 单层输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class 后处理_输出():\n",
    "\tdef __init__(self, 词向量尺寸=100, 隐藏层尺寸=300):\n",
    "\t\tself.隐藏层尺寸 = 隐藏层尺寸\n",
    "\n",
    "\t\tV = uniform(-sqrt(1./隐藏层尺寸), sqrt(1./隐藏层尺寸), (词向量尺寸, 隐藏层尺寸))\n",
    "\t\tself.V = theano.shared(name='V', value=V.astype(theano.config.floatX))\n",
    "\t\tself.mV = theano.shared(name='mV', value=np.zeros(V.shape).astype(theano.config.floatX))\n",
    "\t\tself.参数 = [self.V]\n",
    "\t\tself.rms = [self.mV]\n",
    "\tdef 前向传播(self,输入):\n",
    "\n",
    "\t\tdef 前向_单步(输入_V,V_1):\n",
    "\t\t\t输出_V = V_1.dot(输入_V)\n",
    "\t\t\treturn 输出_V\n",
    "\n",
    "\t\t单层输出, updates = theano.scan(\n",
    "\t\t\tfn = 前向_单步,\n",
    "\t\t\tsequences = [ 输入],\n",
    "\t\t\tnon_sequences = [self.V]\n",
    "\t\t\t)\n",
    "\t\treturn 单层输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_集束():\n",
    "\tdef __init__(self, 词向量尺寸=100, 隐藏层尺寸=300,层数=2,求导深度=-1):\n",
    "\t\tself.层数=层数\n",
    "\t\tself.词向量尺寸=词向量尺寸\n",
    "\t\tself.隐藏层尺寸=隐藏层尺寸\n",
    "\t\tself.求导深度=求导深度\n",
    "\t\tself.参数=[]\n",
    "\t\tself.rms=[]\n",
    "\t\t输入 = T.imatrix('i')\n",
    "\t\t目标输出  = T.imatrix('o')\n",
    "\t\t输入_遮罩= T.fmatrix('mi')\n",
    "\t\t输出_遮罩= T.fmatrix('m0')        \n",
    "\t\t目标长度 = T.iscalar(\"k\") \n",
    "\t\t集束量= T.iscalar(\"b\") \n",
    "        \n",
    "\t\t预处理=预处理_正交(self.词向量尺寸,self.隐藏层尺寸)\n",
    "\t\tself.参数+=预处理.参数\n",
    "\t\tself.rms+=预处理.rms\n",
    "\t\t输出_内=预处理.前向传播(输入)\n",
    "        \n",
    "        \n",
    "\t\tfor i in range(self.层数):\n",
    "\t\t\tGRU层=GRU_单位_集束(self.隐藏层尺寸)\n",
    "\t\t\tself.参数+=GRU层.参数\n",
    "\t\t\tself.rms+=GRU层.rms\n",
    "\t\t\t输出_内=GRU层.前向传播(输出_内,输入_遮罩,集束量)\n",
    "#\t\t信息包=输出_内[-1]\n",
    "\n",
    "\t\t注意力层=GRU_注意力(self.隐藏层尺寸,self.隐藏层尺寸)\n",
    "\t\tself.参数+=注意力层.参数\n",
    "\t\tself.rms+=注意力层.rms            \n",
    "\t\t信息包=注意力层.前向传播(输出_内)            \n",
    "        \n",
    "\t\tGRU层2=GRU_单位2_集束_A(self.隐藏层尺寸)\n",
    "\t\tself.参数+=GRU层2.参数\n",
    "\t\tself.rms+=GRU层2.rms\n",
    "\t\t输出_内2=GRU层2.前向传播(输出_遮罩,集束量,信息包)\n",
    "#\t\t信息包 = theano.printing.Print('this is 信息包 value')(信息包)        \n",
    "\t\tfor i in range(self.层数-1):\n",
    "\t\t\tGRU层=GRU_单位_集束_A(self.隐藏层尺寸)\n",
    "\t\t\tself.参数+=GRU层.参数\n",
    "\t\t\tself.rms+=GRU层.rms\n",
    "\t\t\t输出_内2=GRU层.前向传播(输出_内2,输出_遮罩,集束量) \n",
    "            \n",
    "            \n",
    "\t\t输出层=后处理_输出(self.词向量尺寸,self.隐藏层尺寸)\n",
    "\t\tself.参数+=输出层.参数\n",
    "\t\tself.rms+=输出层.rms\n",
    "\t\t输出_内2=输出层.前向传播(输出_内2)\n",
    "\n",
    "\t\tsoftmax_输出, updates = theano.scan(\n",
    "\t\t\tfn=lambda x: T.nnet.softmax(x.T),\n",
    "\t\t\tsequences=[输出_内2],\n",
    "\t\t\t)\n",
    "# \t\tsoftmax_输出 = theano.printing.Print('this is softmax_输出 value')(softmax_输出)\n",
    "\t\t误差, updates = theano.scan(\n",
    "\t\t\tfn=lambda x,O:T.sum(T.nnet.categorical_crossentropy(x, O)),\n",
    "\t\t\tsequences=[softmax_输出,目标输出],\n",
    "\t\t\t)    \n",
    "\t\t误差 = T.sum(误差)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\t\t参数集_导 = [T.grad(误差, 参数) for 参数 in self.参数]\n",
    "\t\t衰减系数 = T.scalar('L')\n",
    "\t\t学习率_变 = T.scalar('d')\n",
    "\t\trms集= [衰减系数 * rms+ (1 - 衰减系数) * 参数_导 ** 2 for rms, 参数_导 in zip(self.rms, 参数集_导)]        \n",
    "\t\t参数_更新 = [(参数, 参数 - 学习率_变 * 参数_导/ T.sqrt(rms_更新 + 1e-6)) for 参数, 参数_导,rms_更新 in zip(self.参数, 参数集_导,rms集)]\n",
    "\t\trms集_更新=[(rms, rms_更新) for rms,rms_更新 in zip(self.rms,rms集)]\n",
    "\t\t参数_更新+=rms集_更新               \n",
    "        \n",
    "\t\tself.输出_预测 = theano.function(\n",
    "\t\t\t\t\tinputs=[输入,输入_遮罩,输出_遮罩,集束量],\n",
    "\t\t\t\t\toutputs=[softmax_输出],\n",
    "\t\t\t\t\tallow_input_downcast=True,\n",
    "\t\t\t\t\ton_unused_input='ignore'\n",
    "\t\t\t\t\t)\n",
    "        \n",
    "\t\tself.训练 = theano.function(\n",
    "\t\t\tinputs=[输入,输入_遮罩,目标输出,输出_遮罩,集束量,theano.Param(学习率_变, default=0.1), theano.Param(衰减系数, default=0.9)],\n",
    "\t\t\toutputs=[误差],\n",
    "\t\t\tupdates=参数_更新,\n",
    "\t\t\tallow_input_downcast=True,\n",
    "\t\t\t\t\ton_unused_input='ignore'\n",
    "\t\t\t)          \n",
    "        \n",
    "        \n",
    "\tdef 预测(self, 输入,输入_遮罩,输出_遮罩,集束量):\n",
    "\t\t return self.输出_预测(输入,输入_遮罩,输出_遮罩,集束量)\n",
    "\tdef 训练(self, 输入,输入_遮罩,目标输出,输出_遮罩,集束量,学习率,衰减率):\n",
    "\t\t return self.训练(输入,输入_遮罩,目标输出,输出_遮罩,集束量,学习率,衰减率)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "import time\n",
    "词汇总数 =13451\n",
    "学习率 = 1e-3\n",
    "隐藏层尺寸 = 512\n",
    "层数=2\n",
    "\n",
    "# print(包_输入[0].shape[1])\n",
    "# #输出=模型2.预测误差(包_输入[0],包_输出[0],len(包_输出[0]),包_输入[0].shape[1])\n",
    "# 输出=模型2.训练(包_输入[0],包_输出[0],len(包_输出[0]),包_输入[0].shape[1],学习率,0.9)\n",
    "# print(输出[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:81: UserWarning: The Param class is deprecated. Replace Param(default=N) by theano.In(value=N)\n"
     ]
    }
   ],
   "source": [
    "模型2 = GRU_集束(词汇总数 , 隐藏层尺寸,层数)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\py36\\lib\\site-packages\\theano\\tensor\\subtensor.py:2339: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out[0][inputs[2:]] = inputs[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "轮 0 编号 0 13144.098 训练时间 0.7055971622467041\n",
      "轮 0 编号 10 11838.783 训练时间 8.117412328720093\n",
      "轮 0 编号 20 12077.9375 训练时间 15.166855096817017\n",
      "轮 0 编号 30 12181.998 训练时间 22.17899250984192\n",
      "轮 0 编号 40 13072.996 训练时间 29.526125192642212\n",
      "轮 0 编号 50 9527.252 训练时间 36.81300401687622\n",
      "轮 0 编号 60 12165.01 训练时间 43.783461570739746\n",
      "轮 10 编号 0 11328.76 训练时间 505.0467486381531\n",
      "轮 10 编号 10 10460.002 训练时间 512.278555393219\n",
      "轮 10 编号 20 10546.098 训练时间 519.478182554245\n",
      "轮 10 编号 30 10751.404 训练时间 526.6720108985901\n",
      "轮 10 编号 40 11966.244 训练时间 533.9835987091064\n",
      "轮 10 编号 50 8081.5073 训练时间 541.1823704242706\n",
      "轮 10 编号 60 10859.41 训练时间 548.3924095630646\n",
      "轮 20 编号 0 10355.304 训练时间 1009.0517213344574\n",
      "轮 20 编号 10 9235.482 训练时间 1016.0628020763397\n",
      "轮 20 编号 20 9551.25 训练时间 1023.0388171672821\n",
      "轮 20 编号 30 9538.997 训练时间 1030.1131699085236\n",
      "轮 20 编号 40 10559.67 训练时间 1037.316630601883\n",
      "轮 20 编号 50 6788.911 训练时间 1044.7008199691772\n",
      "轮 20 编号 60 9644.483 训练时间 1052.0008516311646\n",
      "轮 30 编号 0 9170.809 训练时间 1500.873844385147\n",
      "轮 30 编号 10 8383.715 训练时间 1507.906108379364\n",
      "轮 30 编号 20 8739.338 训练时间 1514.8997066020966\n",
      "轮 30 编号 30 8695.646 训练时间 1521.9100222587585\n",
      "轮 30 编号 40 9273.664 训练时间 1529.072578907013\n",
      "轮 30 编号 50 5849.7 训练时间 1536.100528717041\n",
      "轮 30 编号 60 8460.511 训练时间 1543.09614610672\n",
      "轮 40 编号 0 7918.522 训练时间 1991.6107795238495\n",
      "轮 40 编号 10 6837.865 训练时间 1998.6717619895935\n",
      "轮 40 编号 20 6904.891 训练时间 2005.842589378357\n",
      "轮 40 编号 30 7146.5913 训练时间 2012.9714698791504\n",
      "轮 40 编号 40 8726.115 训练时间 2020.0857348442078\n",
      "轮 40 编号 50 4837.6177 训练时间 2027.1080679893494\n",
      "轮 40 编号 60 7202.246 训练时间 2034.094928741455\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "for j in range(200):\n",
    "    \n",
    "    for i in range(70):\n",
    "\n",
    "            输出=模型2.训练(包_输入[i],输入_遮罩_集[i],包_输出[i],输出_遮罩_集[i],包_输入[i].shape[1],学习率,0.9)\n",
    "            if (i%10==0 and j%10==0):\n",
    "                t2 = time.time()\n",
    "                print(\"轮\",j,\"编号\",i,输出[-1],'训练时间',(t2 - t1))\n",
    "\n",
    "print (\"单步训练时间: ~%f 秒\" % ((t2 - t1) * 1.))\n",
    "输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(15000)\n",
    "import pickle \n",
    "\n",
    "\n",
    "with open('data/模型2_6_26', \"wb\") as mf:\n",
    "     pickle.dump(模型2, mf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/模型2_6_26', \"rb\") as mf:\n",
    "       模型3= pickle.load(mf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13451"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "输出初步[-1][:,-1,:].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def print_sentence(s, index_to_word):\n",
    "    sentence_str = [index_to_word[x] for x in s[1:-1]]\n",
    "    print(\" \".join(sentence_str))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def generate_sentence(model, index_to_word, word_to_index, min_length=5):\n",
    "    # We start the sentence with the start token\n",
    "    new_sentence = [word_to_index[SENTENCE_START_TOKEN]]\n",
    "    print(new_sentence)\n",
    "    # Repeat until we get an end token\n",
    "    while not len(new_sentence)  < 20:\n",
    "        next_word_probs = model.预测(new_sentence,1)[-1]\n",
    "        samples = np.random.multinomial(1, next_word_probs[-1])\n",
    "        sampled_word = np.argmax(samples)\n",
    "        print(len(new_sentence))\n",
    "        new_sentence.append(sampled_word)\n",
    "        # Seomtimes we get stuck if the sentence becomes too long, e.g. \"........\" :(\n",
    "        # And: We don't want sentences with UNKNOWN_TOKEN's\n",
    "        if len(new_sentence) > 100 or sampled_word == word_to_index[UNKNOWN_TOKEN]:\n",
    "            return None\n",
    "    if len(new_sentence) < min_length:\n",
    "        return None\n",
    "    return new_sentence\n",
    "\n",
    "def generate_sentences2(model, n, index_to_word, word_to_index):\n",
    "    for i in range(n):\n",
    "        sent = None\n",
    "        while not sent:\n",
    "            sent = generate_sentence(model, index_to_word, word_to_index)\n",
    "        print_sentence(sent, index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17872 17859 17827 12421 12971 17714 17814  3230 16627  3282   817 17501\n",
      " 15443 17813 17870]\n"
     ]
    }
   ],
   "source": [
    "print(包_输入[0][:,1])\n",
    "# oph=输入_遮罩_集[0][0,:]\n",
    "# 测试1=1-oph[None,:]\n",
    "# 测试2=np.ones((2,200))\n",
    "# 测试3=测试1*测试2\n",
    "# 测试3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入\n",
      "手机 都 要 50 万 也 太过分 了 稳如 手机 <MASK/> <MASK/> <MASK/>\n",
      "谁 小 ， 不用 ？ 的 ？ 稳 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "精装 的 两万 也 就 买个 沙发 吧 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "最 的 布林德 有 嗨 了 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "+ 1 1 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "1 + 1 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "+ 1 + 1 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "+ 1 + 1 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "id 吓 尿 + 1 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "+ 1 我 楼主 SENTENCE_END 了 SENTENCE_END <MASK/> <MASK/> SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "来 报道 + 1 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "好 还有 感觉 终于 请 一个 的 不 。 了 SENTENCE_END <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "+ 7 + 1 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "+ 1 1 一下 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "朝鲜 100 % 吧 ？ 我 也 是 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "大神 也 也 是 我 就 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "照样 刚 这 id 吊 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "这么 已经 了 作者 了 麻药 瓜 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "666 强 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "李菊福 再 加 ， 叫 你行 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "哈哈哈 。 浓浓的 知音 气息 啊 从 哪 看 出来 的 ？ <MASK/>\n",
      "卧槽 ， 对 说 说 这个 ， 我 不 ？ 水平 演技 SENTENCE_END SENTENCE_END\n",
      "输入\n",
      "中 二 晚期 她 他 么 就是 个 神经病 还 不是 中 二\n",
      "要 和 了 还 是 的 是 是 老哥 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "卧槽 ？ ！ 你 也 逛 曼联 吧 。 <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "我 也 也 也 这个 ！ 的 ！ 你 ！ … … ！ <MASK/>\n",
      "输入\n",
      "可以 ， 这 很 dj 你们 在 聊 什么 我 看不懂 啊 <MASK/>\n",
      "真的 是 ， ， 了 ， ？ ！ SENTENCE_END SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "。 。 。 。 。 我 想起 德佩 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "啦 楼主 一个 一个 太 我 一个 我 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "笑 岔气 没 2333 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "日 了 妹 sb 是 这个 一刻 为啥 在 在 是 在 。 SENTENCE_END\n",
      "输入\n",
      "简直 逆天 了 德佩 都 比 他 强 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "哈哈 看 ， 都 岁 这个 不是 确实 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "这比 踢 假球 啊 笑 尿 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "哈哈 老王 中国 有点 SENTENCE_END SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "阿森纳 也 有 卡里克 ？ 要 滚 这么 多个 圈 ？ <MASK/> <MASK/>\n",
      "稳如 这 基佬 基佬 同 屌 怎么样 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "我 也 想到 德佩 我 想起 c 罗 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "巴萨 还是 还是 ， 这 这 妹纸 代表 球迷 ！ SENTENCE_END <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "包青天 a <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "禽兽不如 你 想 想 婊 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "a 03 无疑 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "马桶 罗 你 第一门 我 86 没 SENTENCE_END <MASK/> SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "97 天龙八部 是 武侠 第一名 a <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "马桶 吧 20 终于 不如 好 … … SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "97 97 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "阔以 层主 ， 1s 我 我 啊 SENTENCE_END SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "第三张 不是 吗 千叶 真一 的 雄霸 估计 没人能 超越 <MASK/> <MASK/> <MASK/>\n",
      "现在 的 张 什么 这是 在 在 ？ SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "焦恩俊 实在 太帅 了 幽若 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "心态 不是 不是 不错 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "必须 小李飞刀 风云 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "笑 尿 笑 SENTENCE_END SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "必须 风云 小李飞刀 ！ 能 驾驭 泡面 头 的 男人 <MASK/> <MASK/> <MASK/>\n",
      "这是 的 人 爆 的 当时 对 了 ？ 了 里斯本 替补 SENTENCE_END <MASK/>\n",
      "输入\n",
      "风云 ~ 风云 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "猜 了 这个 真的 是 一样 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "b 风云 风云 幽若 秒杀 女主 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "老 … 这个 … 娜娜 现在 … 太 了 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "都 没 看过 什么 鬼 ， 听 都 没 听 过 <MASK/> <MASK/>\n",
      "我 都 是 啊 啊 啊 啊 啊 你 要 ， 真 SENTENCE_END <MASK/>\n",
      "输入\n",
      "a 水月 洞天 的 故事 ， 天下第一 的 演员 <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "我 也 图 ， 的 啦 的 人 脚 <MASK/> SENTENCE_END <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "两部 都 不 好看 真 不好 选 啊 . . <MASK/> <MASK/> <MASK/>\n",
      "哈哈哈 了 ， 我 被 这种 → 笑 → SENTENCE_END 。 SENTENCE_END <MASK/> <MASK/>\n",
      "输入\n",
      "我选 95 版 都 喜欢 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "谁 11 ， ， 都 他 ， 大 还 可以 啊 啊 SENTENCE_END <MASK/>\n",
      "输入\n",
      "封神榜 都 不 喜欢 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "这 曼联 废 了 2 ， SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "石榴 姐 真是 演技派 都 喜欢 ， 不选 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "那 还 挺 拍 你 真的 你 <MASK/> SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "没 看过 陆小凤 ！ <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "肯定 ！ 帖子 ！ 来 这个 。 来 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "没 看过 废物 ！ <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "肯定 ！ 帖子 ！ 来 这个 。 来 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "港版 b 简直 就是 垃圾 剧 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "@ ～ 要 教授 看 不 了 不错 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "你 妈 死 了 两个 都 太 好看 了 <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "你 了 没有 了 了 太 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "啊 啊 a 你 全家 死 了 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "回复 笑 ， 就 了 吧 笑 笑 的 吧 这是 SENTENCE_END SENTENCE_END <MASK/>\n",
      "输入\n",
      "明显 是 情 深深 b <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "确实 曼联 漂亮 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "a b <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "多 好 毛病 SENTENCE_END SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "83 a <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "《 30 前面 写 写 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "94 94 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "明白人 层主 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "b 94 ， 因为 朱茵 。 。 。 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "我 。 才 了 这 可以 ？ 我 。 ？ SENTENCE_END SENTENCE_END <MASK/> <MASK/>\n",
      "输入\n",
      "94 ， 朱茵 黄蓉 是 真 厉害 83 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "啥 才 没 最 蛤 是 当时 当时 当时 鲁尼 不愧 SENTENCE_END SENTENCE_END <MASK/>\n",
      "输入\n",
      "94 巅峰 朱茵 83 黄蓉 完爆 其他 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "最后 搞笑 都 都 得 的 。 赞成 4 5 还是 真的 SENTENCE_END <MASK/>\n",
      "输入\n",
      "朱茵 83 烂片 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "吼吼 这是 四 我 我 有 继续 那 是 助攻王 吗 ？ SENTENCE_END <MASK/>\n",
      "输入\n",
      "温碧霞 鲁 初雪 a <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "你好 大 感觉 回复 去 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "圆月 弯刀 圆月 弯刀 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "6 .5 SENTENCE_END SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "a ， 又 是 一部 伴 我 成长 的 剧 包青天 很 经典\n",
      "林 的 看过 都 好 好 SENTENCE_END SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "我 选择 死亡 。 。 一 配乐 好听 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "这 ， 我 ， 确实 我 加 连败 1 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "a 都 不是 一个 档次 寻秦记 吊打 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "腾讯 么 是 没 撸 是 没 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "当然 寻秦记 寻秦记 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "稳如 又 啪啪 ， 我 都 的 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "都 没 看过 侮辱 寻秦记 啊 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "？ ？ 了 不是 这 还有 还有 么 SENTENCE_END SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "9 9 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "布林德 0 分 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "东方 教主 a <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "逆天 速度 可惜 不是 b 了 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "比起 小笼包 ， 还是 香肠 好 一些 都 是 垃圾 <MASK/> <MASK/> <MASK/>\n",
      "好 了 是 感觉 爆 呢 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "a a <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "ck 来 的 来看 bilibili SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "必须 a a <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "萨 好久 我 好 SENTENCE_END SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "b 是 我 唯一 完整 看过 两遍 的 武侠剧 这个 ， 我选 b\n",
      "感觉 感觉 ， 球 ？ 后 脸 你 好 SENTENCE_END SENTENCE_END <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "a b <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "多 好 毛病 SENTENCE_END SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "b a <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "好汉 第一 啊 我要 的 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "b b <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "煞笔 傻 哈哈 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "b 和 大人 太 搞笑 好难 ， 平手 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "我 的 时代 逼 这么 不好 一个 … SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "你 想 影射 什么 ？ 最后 时刻 扳平 的 <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "发 知道 知道 不 的 手机 你 你 知道 知道 ， 脚 脚 SENTENCE_END\n",
      "输入\n",
      "小 司机 傻 屌 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "屌 逼 逼 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "你 女朋友 有 小弟弟 ？ 你 女朋友 的 性格 肯定 超级 好 ！\n",
      "有 人 ， 逼 有 的 记得 ？ SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "有 两个 然后 呢 ？ <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "？ 球 ？ ， SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "唉 · · · · · · 恩 ， 女友 哪里 人 ？\n",
      "前排 瞎 瞎 了 这 祝 了 你们 好运 这 这 <MASK/> SENTENCE_END <MASK/>\n",
      "输入\n",
      "涨 姿势 ！ 马可 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "不 … 好 了 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "丧尸 愿闻其详 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "何德何能 啊 还 第一门 将 我 没 多 多 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "其实 楼主 主要 想 问 的 就是 这个 不是 <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "是 不是 了 很 不是 SENTENCE_END SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "恩 说 的 没错 你 哪里 人 啊 ？ 山东 <MASK/> <MASK/> <MASK/>\n",
      "去 是 没 ？ 看 你 淫 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "lms 也 不 知道 是 什么 耶 打多 打少 都 是 缘 <MASK/>\n",
      "师奶 id 5 。 ！ ！ 5 中出 此贴 SENTENCE_END SENTENCE_END <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "心疼 楼主 心疼 楼主 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "+ 楼主 我 楼主 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "生日快乐 呀 啦 啦 啦 啦 啦 啦 啦 谢 啦 <MASK/> <MASK/>\n",
      "99 是 好 右后卫 擦 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "不要 乖 ， 要 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "是 我 有 我 我 我 我 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "好 麻烦 啊 吃 了 吗 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "在 还有 了 没 我 ， 啊 ？ SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "我 没 吃 咋 不吃 啊 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "nba 现在 不到 时候 吧 时候 … … SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "重伤 废 了 真 可惜 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "低 了 了 去 至少 SENTENCE_END 吗 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "暖 泥煤 又 开学 了 。 又 要 往 你们 宁波 跑 了\n",
      "看 感觉 不 你们 了 不 一个 没 ， ， ， 可以 可以 SENTENCE_END\n",
      "输入\n",
      "不 懂 幽默 沙壁 玩意 @ 曼联 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "操 ， 真 阿 是 后 好 ， 好 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "不让 他 碰到 不 就 好 了 舒马赫 啊 ？ 倒 着 开车\n",
      "楼主 我 今年 还是 ？ 是 ？ 了 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "sb 越位 线 线 是 对 的 。 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "噗 像 对 ， 的 。 。 ！ 。 笑 笑 废 SENTENCE_END SENTENCE_END\n",
      "输入\n",
      "皇马 的 名字 妈 的 白 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "原来 挺 ！ 就 老 你 你 夏天 SENTENCE_END SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "不是 么 ， 梅西 94 ， c 罗 93 <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "还 啊 谢谢 之王 的 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "其实 很 耐看 资瓷 麦克 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "-- ， 记得 只有 黄驴 的 减 一亿 过去 第三 ) SENTENCE_END <MASK/> <MASK/>\n",
      "输入\n",
      "关键 是 气质 啊 ， 完全 不同 了 。 邢 捕头 忧郁 的\n",
      "一个 不错 谁 是 懂 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "没错 炮王 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "啊 66666 有 我 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "卡里克 应该 是 最后 一年 了 一个个 都 要 离开 了 <MASK/> <MASK/>\n",
      "啥 的 了 0 了 ， 时间 时间 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "期待 北京 奥运会 我 也 是 。 刘翔 加油 <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "身体 踢 名宿 还是 觉得 联系方式 多 的 说 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "太监 了 什么 太监 不是 完 了 吗 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "被 了 娜娜 他 娜娜 他 像 逗 了 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "我 女朋友 咯 药店 碧莲 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "96 官宣 被 被 被 代表 顺便 代表 去 我 SENTENCE_END <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "镇楼 是 谁 我 女朋友 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "我 ！ 女友 也 东西 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "还 在 用 8 5s <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "笑 眼睛 了 的 不 把 把 把 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "6 8 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "8 8 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "0 现代 装 8 分 ， 古装 0 分 <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "老王 分 过 防守 2 满分 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "7 .5 6 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "6 6 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "赞同 6 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "6 这个 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "4 6 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "6 6 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "古装 负分 只要 不是 古装 就 好 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "没 叫 好 一个 一个 完 叫 的 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "100 分 2 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "2 他娘 ， q SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "6 6 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "6 6 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "霍 建华 7 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "马克 这个 吧 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "3 9 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "布林德 0 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "8 6 分 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "10 分 8 .5 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "10 分 ， 真心 帅炸 了 7 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 10 ， ， 很 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "9 我 又 一次 赞同 你 ！ <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "我 我 挺 终于 挺 好 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "9 7 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "7 8 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "100 分 6 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "6 0 SENTENCE_END SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "7 8 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "8 10 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "8 9 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "9 8 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "8 7 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "7 7 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "7 3 分 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "9 分 请问 低 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "1 5 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "5 我 SENTENCE_END SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "5 我 抬 球迷 75 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "我 ， 人 被 好 的 的 SENTENCE_END <MASK/> <MASK/> SENTENCE_END <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "8 7 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "7 7 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "不 喜欢 他 的 眼睛 ， 其他 都 挺 好 7 <MASK/> <MASK/>\n",
      "- - - 还 还 把 还 霸气 的 SENTENCE_END SENTENCE_END <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "真假 ？ 面瘫 居然 ？ 负分 滚 粗 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "有 这 欧冠 都 逼 都 没得 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "9 .9 5 分 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "5 分 8 SENTENCE_END <MASK/> SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "9 分 9 .5 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "9 .5 9 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "9 8 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "8 9 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "10 8 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "8 10 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "10 10 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "10 马 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "车祸 前 10 ， 车祸 后 7 9 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "3 不到 3 0 0 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "王子 文 5 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "老哥 因为 一个 还 ， 到 ， 到 还 还 还 还 SENTENCE_END SENTENCE_END\n",
      "输入\n",
      "7 . 7 .5 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "7 分 8 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "看见 狗狗 也 想 笑 娜 拿 什么 跟 曼联 比 啊 <MASK/>\n",
      "哈哈 ， 快 去 去 去 去 去 去 哪里 太 SENTENCE_END SENTENCE_END <MASK/>\n",
      "输入\n",
      "娜 婊 好气 啊 ， 巡逻 了 赖 着 不想 走 ！ 狗狗\n",
      "更 ， 娜 他 是 这个 你 这种 这种 你 SENTENCE_END 这个 SENTENCE_END <MASK/>\n",
      "输入\n",
      "sb 娜 婊 煞笔 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "呵呵 很 @ @ 要 @ <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "智障 贱货 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "稳如 死 都 ， 好像 好像 好像 ， ， ， SENTENCE_END 。 <MASK/> <MASK/>\n",
      "输入\n",
      "同 同 ， 我们 老 了 啊 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "层主 看 和 ， … 了 根本 了 吃 ？ SENTENCE_END <MASK/> SENTENCE_END <MASK/>\n",
      "输入\n",
      "佩服 别 ， 不好意思 了 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "前 还 经常 还 刚 还 还 还 ？ SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "这样 还 12 级 ？ 我 这样 就 不能 是 12 级 ？\n",
      "这么 … 啊 … … 了 比赛 笑 笑 … SENTENCE_END SENTENCE_END <MASK/> <MASK/>\n",
      "输入\n",
      "这点 说 的 太好了 有 道理 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "哪里 我 表示 也 为什么 SENTENCE_END SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "悬 你 也 觉得 我 说 的 对 吧 <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "你 是 我 我 他 你 马拉多纳 我 了 么 了 SENTENCE_END <MASK/> <MASK/>\n",
      "输入\n",
      "凯尔特人 教练 是 罗 爵爷 吗 ？ 是 哒 <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "是 的 有 都 ？ ？ SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "好 法尔考 马 竞 那年 真心 稳 ， <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "泪奔 ， 。 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "看不懂 ？ 和 陈冠希 搞基 搞基 陈冠希 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "没什么 在 半个 了 了 买下 ， 明显 起来 明显 才 喜欢 版 。\n",
      "输入\n",
      "正 解 这楼 三观 正 ， 还是 有 希望 的 <MASK/> <MASK/> <MASK/>\n",
      "好 人 知道 的 的 的 是 的 的 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "笑 尿 破 吧 就 服 你 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "这个 你 你 。 是 。 id @ 婊 哈哈哈 ： 屌 SENTENCE_END <MASK/>\n",
      "输入\n",
      "看 不了 a 站 字幕 翻译 有 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "好 才 我 这个 这个 这个 有 也 有 看看 SENTENCE_END <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "这种 片 ， 弹幕 最 重要 预警 吗 ？ <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "那 吗 ？ 有 绝对 都 都 都 的 是 是 鲁尼 了 SENTENCE_END\n",
      "输入\n",
      "这片 不 需要 预警 吧 ， 一点 都 不 恐怖 谁 知道 呢\n",
      "都 吧 ， 都 逼 是 最 逼 的 哈哈哈 <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "一语道破 haha <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "蓝 6 就 就 <MASK/> SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "皇家 狗 德里 马戏团 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "车牌 你好 要 去 恨 里 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "黄狗 稳 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "稳 你 SENTENCE_END SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "黄狗 贵族 伤不起 ， 皇家 马德里 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "这是 好玩 ， ， 助攻 了 ， 就是 防 同时 了 了 SENTENCE_END <MASK/>\n",
      "输入\n",
      "不是 巴 傻 嘛 巴狗 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "求 给 很 刁钻 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "傻狗 拉玛 西亚 影视 学院 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "苟 6 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "一日 红蓝 ， 终生 脑残 巴狗 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "稳如 个 那 我 贴 兄弟 贴 @ @ 他 吧 <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "梦之队 巴狗 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "吉个斯 鸡鸡 咩 SENTENCE_END SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "死个 马 奥斯卡 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "恶心 第一 吗 ， 觉得 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "巴 傻 全家 暴毙 巴 傻 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "狗 我 比 演得 我 的 我 的 我 只是 SENTENCE_END <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "八 傻 巴狗 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "马克 前排 SENTENCE_END SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "不是 七喜 吗 稳 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "稳 稳 你 ， 怎么 更 更 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "巴狗 巴 傻 全家 暴毙 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "狗 不 — 配置 的 和 和 路过 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "巴狗 拉影 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "有意思 鸡鸡 果然 姐妹 SENTENCE_END <MASK/> <MASK/> 吗 <MASK/> SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入\n",
      "巴狗 死个 妈 先 演员 队 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "百度 直接 一个 一个 看 看 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "一日 白衣 ， 终身 傻 b ？ 看得出来 ， 真 红蓝 魂 <MASK/>\n",
      "终于 这个 叫 就 一起 才 才 我 哈哈哈哈 ？ <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "为什么 他们 不 叫 床单 ？ 就 你 话 多 <MASK/> <MASK/> <MASK/>\n",
      "就 是 是 是 打 你 真 的 就是 吧 SENTENCE_END <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "他 抬 我 大红 魔 ， 快快 崛起 吧 <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "有 有 我 都 有 有 有 ？ 有 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "我 魔 合影 抬 你 咋 地 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "有 有 有没有 我 可以 为什么 我 看过 我 … SENTENCE_END <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "欧洲 亚军 杯 ， 拜仁 慕尼黑 五仁 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "鲁尼 ， ， 有 那 ， 有 有 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "移动 队 分期 队 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "层主 挺 ， 的 了 确实 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "队徽 上 也 有 两只 喵 就 你 话 多 <MASK/> <MASK/> <MASK/>\n",
      "我 这么 🐶 吧 这 手机 退役 了 ！ <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "美国 粑 粑 截图 都 不会 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "这个 应该 看 的 看 是 同意 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "翻译 辛苦 了 好久没 看见 你 了 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "牛 你 ~ 笑 SENTENCE_END SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "多么 痛 的 领悟 多么 疼 的 领悟 啊 <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "你 应该 啊 有 ？ ？ ？ ？ 啊 啊 SENTENCE_END <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "色贤 就是 华为 造 的 鸡鸡 淫 我 去 ， jj 人 说话\n",
      "队长 感觉 一个 0 他 你们 就是 把 了 把 <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "截屏 在 这 图 都 绿 了 ， 滚 <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "这个 不 还 ， 还 人 恐怖 人 恐怖 啊 ， ， SENTENCE_END <MASK/>\n",
      "输入\n",
      "四川 肖国吉 肠胃 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "是 只有 和 有 司机 比 皇马 有 何不 。 。 SENTENCE_END <MASK/> <MASK/>\n",
      "输入\n",
      "就是 那个 队 … … 全国 跑 不会 吧 <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "好 还 喜欢 ， 做 还 有点 ， 我 啊 了 ？ SENTENCE_END <MASK/>\n",
      "输入\n",
      "还 真 尼玛 就 一脚 哈哈 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "这个 回复 . ， 一样 一样 ， 一样 行 吧 吧 。 。 SENTENCE_END\n",
      "输入\n",
      "队 … … 队长 ？ 倒钩 那个 ？ <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "谁 被 维 有 ？ 吗 吗 买 的 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "我 抬 名宿 盖坦 前段时间 好像 刚 续约 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "还是 下 上 一直 可以 欢迎 向 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "970 现在 多少 钱 啊 ？ 970 要 1000 多 吧 <MASK/> <MASK/>\n",
      "哪个 ， ， ， 没 没 ， ？ SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "0708 赛季 曼联 没有 任何 缺点 的 球队 中场 还是 差点 <MASK/> <MASK/>\n",
      "99 的 级 的 这是 ？ 么 ？ SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "哥 02 开始 看 呵呵 。 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "这 就 这么 ， 留 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "破 吧 我 就 服 你 服 ！ ！ ！ <MASK/> <MASK/> <MASK/>\n",
      "可以 的 老哥 我 觉得 还是 挺 好看 的 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "什么 图 ？ 不会 动 吗 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "太 的 级别 看 一笔 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "妈个 比 ， 这么 基情 ？ 这图 来看 赛后 喝酒 是 没 问题\n",
      "官宣 吧 百度 都 还有 一亿 卡 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "什么 时候 的 咱 也 握个 ？ 拉 鸡巴 倒 吧 <MASK/> <MASK/>\n",
      "靠 这个 图 么 可以 可以 · SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "看 硬 了 这是 哪一年 的 事 ？ <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "这个 那 错 还 是 你 就是 吹 了 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "基情 四射 2011 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "喜欢 得 。 月 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "sb ， 你 看球 了 吗 ？ 不是 曼城 球权 你 吃屎 ？\n",
      "小 是 更 过 的 又 了 确实 啊 ？ SENTENCE_END <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "你 爹 ？ 你 爷爷 ？ <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "你 ？ 逗 大 哪个 ！ ！ ， 好 ！ SENTENCE_END <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "32 强 不是 要 32 平了 他 带领 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "毕竟 足球 就是 我要 的 过 当 不能 的 。 SENTENCE_END <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "此话 怎么 讲 多 运动 。 运动 改变 人生 <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "月 穆里尼奥 叫 ， ， ， 到 到 ， … SENTENCE_END SENTENCE_END <MASK/> <MASK/>\n",
      "输入\n",
      "书 还是 电影 ？ 书 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "罗 嫪毐 ？ 玻璃 b 估计 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "卧槽 帮 你 找到 老婆 了 ， 怎么 说 ？ <MASK/> <MASK/> <MASK/>\n",
      "我 是 我 就 之前 哈哈 SENTENCE_END SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "感觉 是 4 比 3 3 比 2 这种 比分 别 <MASK/> <MASK/>\n",
      "8 一般 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "开个 价 吧 最近 两年 输 了 多少 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "那个 不 ， ， ， 后面 ， 世界杯 么 ， 2 SENTENCE_END <MASK/> <MASK/>\n",
      "输入\n",
      "不去 卧底 可惜 了 这 id 碉堡 了 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "低 女 他 了 长大 尿 小龙 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "去 表妹 吧 玩 潜伏 吧 未必 ， 斯坦科 维奇 知道 吗 。\n",
      "还 啊 他 过 ， 来 我 跟 ？ ？ SENTENCE_END <MASK/> <MASK/> <MASK/>\n",
      "输入\n",
      "少 了 个 大卫 席尔瓦 嗯 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "老 那个 真的 了 巴 只能 真的 只能 ， 猜 喜欢 的 顶 SENTENCE_END\n",
      "输入\n",
      "最后 两位 数字 怎么 算 ？ 14 + 35 - 2 <MASK/> <MASK/>\n",
      "嗯 那么 这场 也 ， ， 多 男 那个 吗 吗 ， SENTENCE_END <MASK/>\n",
      "输入\n",
      "火烧 你 <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n",
      "是 百度 来 来 一次 SENTENCE_END <MASK/> SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/>\n"
     ]
    }
   ],
   "source": [
    "for j in range(51,52):\n",
    "#     p2=p.ones_like(输入_遮罩_集[j])\n",
    "    结果_1=模型3.预测(包_输入[j],输入_遮罩_集[j],输入_遮罩_集[j],包_输入[j].shape[1])\n",
    "\n",
    "    \n",
    "    for k in range(结果_1[-1].shape[1]):\n",
    "        new_sentence = [单词_到_下标[SENTENCE_START_TOKEN]]\n",
    "        for i in range(len(结果_1[-1][:,k,:])):\n",
    "        #samples = np.random.multinomial(1, 结果[-1][i])\n",
    "            \n",
    "\n",
    "            sampled_word = np.argmax(结果_1[-1][i,k,:])\n",
    "\n",
    "            new_sentence.append(sampled_word)\n",
    "\n",
    "        if j>=0:\n",
    "\n",
    "            #print(\"次数\",j )\n",
    "            print(\"输入\" )\n",
    "            print_sentence(包_输入[j][:,k], 下标_到_单词)\n",
    "            #print(\"目标输出\" )\n",
    "            #print_sentence(包_输出[j][:,k], 下标_到_单词)\n",
    "            #print_sentence(X_train[j], 下标_到_单词)\n",
    "            #print(包_输入[j][:,k])\n",
    "            \n",
    "            print_sentence(new_sentence, 下标_到_单词)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role A: 你 好 啊\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role A: 永远 活在 上赛季 ？ 永远 看 一个 赛季 \n",
      "(9, 1)\n",
      "(9, 1)\n",
      "永远 看 一个 赛季 ？ 怎么 感觉 你 是 说 给 层主 听 的\n",
      "role A: 永远 活在 上赛季 ？\n",
      "(5, 1)\n",
      "(5, 1)\n",
      "永远 知道 你 怎么 ？ 怎么 怎么 说 ， 怎么 没 是 层主 的\n",
      "role A: 漂亮 厉害 了 ， 我 的哥\n",
      "(7, 1)\n",
      "(7, 1)\n",
      "厉害 了 ， 我 的哥 这 算是 最 成功 的 过 人 了 SENTENCE_END\n",
      "role A: 漂亮 厉害 了 我 的哥\n",
      "(6, 1)\n",
      "(6, 1)\n",
      "厉害 了 我 看 想 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> SENTENCE_END <MASK/>\n",
      "role A: 漂亮 厉害 了 ， 我 的哥\n",
      "(7, 1)\n",
      "(7, 1)\n",
      "厉害 了 ， 我 的哥 这 算是 最 成功 的 过 人 了 SENTENCE_END\n",
      "role A: 漂亮 厉害 了 我 的哥\n",
      "(6, 1)\n",
      "(6, 1)\n",
      "厉害 了 我 看 想 SENTENCE_END <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> <MASK/> SENTENCE_END <MASK/>\n",
      "role A: 343434\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'343434'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-8f591f74f91f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0m问话_表\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m问话1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0m问话_下标\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m单词_到_下标\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m问话_分\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m问话_分\u001b[0m \u001b[1;32min\u001b[0m  \u001b[0m问话_表\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0m长度\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m问话_下标\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0m问话_下标\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m问话_下标\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-8f591f74f91f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0m问话_表\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m问话1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0m问话_下标\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m单词_到_下标\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m问话_分\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m问话_分\u001b[0m \u001b[1;32min\u001b[0m  \u001b[0m问话_表\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0m长度\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m问话_下标\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0m问话_下标\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m问话_下标\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '343434'"
     ]
    }
   ],
   "source": [
    "\n",
    "def clearn_str(s):\n",
    "\ts = re.sub(r\"\\s+\", \" \", s)\n",
    "\ts = re.sub(r\"\\-\", \"\", s)\n",
    "\treturn 'SENTENCE_START '+s\n",
    "\n",
    "def tokenize(s):\n",
    "\t\"\"\"\n",
    "\tvery raw tokenizer\n",
    "\t\"\"\"\n",
    "\t#s = clearn_str(s)\n",
    "\treturn s.strip().split(\" \")\n",
    "for ai in range(100):\n",
    "    \n",
    "\n",
    "    问话= input(\"role A: \")\n",
    "    问话1=clearn_str(问话)\n",
    "\n",
    "    问话_表=tokenize(问话1)\n",
    "\n",
    "    问话_下标=[单词_到_下标[问话_分] for 问话_分 in  问话_表]\n",
    "    长度=len(问话_下标)\n",
    "    问话_下标=np.array(问话_下标)\n",
    "   # print(问话_下标)\n",
    "    问话_下标=问话_下标.reshape(长度,1)\n",
    "    遮罩_入=np.ones_like(问话_下标)\n",
    "    print(问话_下标.shape)\n",
    "    print(遮罩_入.shape)\n",
    "    for 计数1 in range(15-长度):\n",
    "        问话_下标=np.append(问话_下标,0)\n",
    "        遮罩_入=np.append(遮罩_入,0)\n",
    "    问话_下标=问话_下标.reshape((15,1))\n",
    "    遮罩_入=遮罩_入.reshape((15,1))\n",
    "    遮罩_出=np.ones((15,1))\n",
    "    结果_1=模型2.预测(问话_下标,遮罩_入,遮罩_出,问话_下标.shape[1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for k in range(结果_1[-1].shape[1]):\n",
    "        new_sentence = [单词_到_下标[SENTENCE_START_TOKEN]]\n",
    "        for i in range(len(结果_1[-1][:,k,:])):\n",
    "            #samples = np.random.multinomial(1, 结果[-1][i])\n",
    "\n",
    "\n",
    "            sampled_word = np.argmax(结果_1[-1][i,k,:])\n",
    "\n",
    "            new_sentence.append(sampled_word)\n",
    "\n",
    "        if j>=0:\n",
    "\n",
    "\n",
    "\n",
    "            print_sentence(new_sentence, 下标_到_单词)\n",
    "    #print_sentence(问话_下标, 下标_到_单词)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[2.0278843e-08, 1.4345335e-08, 1.3121954e-08, ...,\n",
       "          1.2518979e-08, 1.2646030e-08, 1.1545746e-08]],\n",
       " \n",
       "        [[4.2733075e-09, 1.8196946e-12, 1.4060009e-12, ...,\n",
       "          1.4425589e-12, 9.9022689e-13, 8.3998758e-13]],\n",
       " \n",
       "        [[3.2288671e-02, 8.5213379e-08, 8.5515246e-08, ...,\n",
       "          6.9670826e-08, 8.2567709e-08, 8.4449916e-08]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[9.9999106e-01, 2.2133615e-15, 2.2436844e-15, ...,\n",
       "          1.7776041e-15, 2.1180311e-15, 2.0279282e-15]],\n",
       " \n",
       "        [[9.9999750e-01, 6.7506461e-16, 6.6548155e-16, ...,\n",
       "          5.6314970e-16, 6.9366429e-16, 6.0339520e-16]],\n",
       " \n",
       "        [[9.9999940e-01, 6.3851821e-16, 6.4512618e-16, ...,\n",
       "          5.2832531e-16, 6.9435129e-16, 5.7587690e-16]]], dtype=float32)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 200)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "包_输入[-1].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
